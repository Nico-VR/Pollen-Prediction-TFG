{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a68c0a7ee0c066a",
   "metadata": {},
   "source": [
    "# 2.1 Forecasting using MOIRAI Foundation Model and sktime\n",
    "\n",
    "In this notebook we will perform zero-shot predictions with and without covariates with the following fundational model for time series prediction: [MOIRAIForecaster](https://www.sktime.net/en/latest/api_reference/auto_generated/sktime.forecasting.moirai_forecaster.MOIRAIForecaster.html#rb64756c851d6-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1def9b44-a1d9-45a3-ba27-a70ba2a7a7ed",
   "metadata": {},
   "source": [
    "## 1. MOIRAI\n",
    "### 1.1. Features\n",
    "\n",
    "[GitHub](https://github.com/SalesforceAIResearch/uni2ts?tab=readme-ov-file#-getting-started) and here you can see that:\n",
    "- **Context Length**: any positive integer\n",
    "- **Horizon Length**: any positive integer\n",
    "\n",
    "Furthermore, in this [paper](https://arxiv.org/pdf/2402.02592) section *D.4. Computation Costs* (page 23) tests are carried out with **Context Length** and **Prediction Length** of up to 5000 datapoints.\n",
    "\n",
    "[Click here](https://huggingface.co/collections/sktime/moirai-variations-66ba3bc9f1dfeeafaed3b974) to check the different versions available of the model, and here you can see that:\n",
    "- **Last Update**: Sept, 2024\n",
    "\n",
    "In addition, in sktime the model has the following characteristics that you can consult in [sktime](https://www.sktime.net/en/latest/api_reference/auto_generated/sktime.forecasting.moirai_forecaster.MOIRAIForecaster.html#rb64756c851d6-1) or in the [Git repo](https://github.com/sktime/sktime/blob/main/sktime/forecasting/moirai_forecaster.py#L21-L653):\n",
    "- **Univariate**: predicts a single dependent variable.\n",
    "- **Covariates**: allows the inclusion of covariates per entry\n",
    "\n",
    "### 1.2. Errors\n",
    "1. It won't let me work with a ```target_dim``` less than 2. In our case, it's only 1: ```pollen```.\n",
    "2. If you change the value from zero to any of the parameters ```num_feat_dynamic_real```, ```num_past_feat_dynamic_real```, it starts throwing errors that I don't know how to solve."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e95ceb3845c16c",
   "metadata": {},
   "source": [
    "## 2. Environment configuration\n",
    "1. **Open PyCharm, or your preferred IDE, with Admin privileges.**\n",
    "2. Install a version of ```python``` compatible. I installed python 3.10.11. not older, ...\n",
    "3. Install a version of ```cuda``` compatible. I installed cuda v12.4 not older v12.6, ...\n",
    "4. Install a version of ```pythorch``` compatible. I use Windows and installed it with the following command ([pytorch previous-versions](https://pytorch.org/get-started/previous-versions/#linux-and-windows)):\n",
    "    ```\n",
    "    pip install torch==2.6.0 torchvision==0.21.0 torchaudio==2.6.0 --index-url https://download.pytorch.org/whl/cu124\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9234feb3-7dbe-4d81-8405-dae8ca16457c",
   "metadata": {},
   "source": [
    "5. To **import the Python modules that we have created locally in the project** we do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3a8dd12-ea10-4292-89e6-59b05be500d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T07:04:41.012148Z",
     "start_time": "2025-06-06T07:04:41.005116Z"
    },
    "execution": {
     "iopub.execute_input": "2025-07-28T14:25:05.866567Z",
     "iopub.status.busy": "2025-07-28T14:25:05.866438Z",
     "iopub.status.idle": "2025-07-28T14:25:05.868547Z",
     "shell.execute_reply": "2025-07-28T14:25:05.868407Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# path to the notebook\n",
    "notebook_path = Path().resolve()\n",
    "\n",
    "# path to the project root (path to ppf)\n",
    "project_path = notebook_path.parents[0]\n",
    "\n",
    "# path to the directory where is placed the source code of the project  (path to ppf/src/ppf/)\n",
    "code_project_path = notebook_path.parents[0] / 'src'  / 'ppf'\n",
    "\n",
    "# insert the paths where to search for python modules (import)\n",
    "sys.path.insert(0, str(code_project_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f14fba9-bc95-4d0c-ac11-71d923bfee27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T14:25:05.869407Z",
     "iopub.status.busy": "2025-07-28T14:25:05.869349Z",
     "iopub.status.idle": "2025-07-28T14:25:05.870659Z",
     "shell.execute_reply": "2025-07-28T14:25:05.870535Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.path:\n",
      "  /home/michi/Workspaces/Python/ppf/src/ppf\n",
      "  /home/michi/miniconda3/envs/ppf-chronos-manual/lib/python312.zip\n",
      "  /home/michi/miniconda3/envs/ppf-chronos-manual/lib/python3.12\n",
      "  /home/michi/miniconda3/envs/ppf-chronos-manual/lib/python3.12/lib-dynload\n",
      "  \n",
      "  /home/michi/miniconda3/envs/ppf-chronos-manual/lib/python3.12/site-packages\n"
     ]
    }
   ],
   "source": [
    "print(\"sys.path:\")\n",
    "for p in sys.path:\n",
    "    print(\" \", p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ecc63c-4d18-48bd-9215-d623c3c8807c",
   "metadata": {},
   "source": [
    "## 3. Obtain pollen predictions\n",
    "### 3.1 Without covariates\n",
    "#### 3.1.1 Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "924c4e8d-aef5-4926-9495-b1a3282daff1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T14:25:05.871255Z",
     "iopub.status.busy": "2025-07-28T14:25:05.871205Z",
     "iopub.status.idle": "2025-07-28T14:25:06.010059Z",
     "shell.execute_reply": "2025-07-28T14:25:06.009768Z"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import date, timedelta\n",
    "import pandas as pd\n",
    "\n",
    "FIRST_YEAR = 1993\n",
    "LAST_YEAR = 2023\n",
    "\n",
    "# First and last day in the datset\n",
    "FIRST_DATE = date(FIRST_YEAR, 1, 1)\n",
    "LAST_DATE = date(LAST_YEAR, 12, 31)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45653666-8566-4b46-8b5d-6c334865462f",
   "metadata": {},
   "source": [
    "#### 3.1.2 Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1da6eb03-3196-4a46-bea0-558a61069bba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T14:25:06.011110Z",
     "iopub.status.busy": "2025-07-28T14:25:06.011008Z",
     "iopub.status.idle": "2025-07-28T14:25:06.012332Z",
     "shell.execute_reply": "2025-07-28T14:25:06.012201Z"
    }
   },
   "outputs": [],
   "source": [
    "# 1 week of horizon\n",
    "HORIZON_SIZE = 7\n",
    "\n",
    "# 1 year of context\n",
    "INPUT_SIZE = 365 \n",
    "\n",
    "# 0 year of training (zero-shot, no fitting)\n",
    "TRAIN_SIZE = 0\n",
    "\n",
    "# benchmark for 2000, 2001, ..., 2021, 2022 (22 years)\n",
    "START_YEAR = 2000\n",
    "END_YEAR = 2022\n",
    "\n",
    "# half a yar of offset days\n",
    "OFFSET_DAYS = -182"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "659c0b5d-0b63-44d4-a915-d025d0046a46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T14:25:06.013006Z",
     "iopub.status.busy": "2025-07-28T14:25:06.012945Z",
     "iopub.status.idle": "2025-07-28T14:25:06.014857Z",
     "shell.execute_reply": "2025-07-28T14:25:06.014724Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1998-06-27\n",
      "1998-06-27\n",
      "2023-01-06\n"
     ]
    }
   ],
   "source": [
    "from non_leap_date_utils import calculate_non_leap_offset_dates, add_non_leap_days\n",
    "\n",
    "# obtener todas la fecha necesarias\n",
    "START_TRAINING, _ = calculate_non_leap_offset_dates(START_YEAR, END_YEAR, INPUT_SIZE, TRAIN_SIZE, OFFSET_DAYS, HORIZON_SIZE)\n",
    "START_DATE, END_DATE = calculate_non_leap_offset_dates(START_YEAR, END_YEAR, INPUT_SIZE, 0, OFFSET_DAYS, HORIZON_SIZE)\n",
    "print(START_TRAINING)\n",
    "print(START_DATE)\n",
    "print(END_DATE)\n",
    "\n",
    "if START_TRAINING < FIRST_DATE or LAST_DATE < END_DATE:\n",
    "    print(f\"Data younger than {FIRST_DATE} or older than {LAST_DATE} cannot be retrieved from the dataset. Therefore a subset will be obtained.\")\n",
    "    amount_missing_data = (END_DATE - LAST_DATE).days\n",
    "else:\n",
    "    amount_missing_data = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "931ee574-c0bf-4c38-9d7d-ba315ed19639",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T14:25:06.015500Z",
     "iopub.status.busy": "2025-07-28T14:25:06.015446Z",
     "iopub.status.idle": "2025-07-28T14:25:06.016653Z",
     "shell.execute_reply": "2025-07-28T14:25:06.016538Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Output directory for predictions\n",
    "PREDICTIONS_DIR = \"../outputs/predictions\"\n",
    "# Output directory for models runtime\n",
    "TIMING_DIR = \"../outputs/timing\"\n",
    "# Create the directory\n",
    "os.makedirs(PREDICTIONS_DIR, exist_ok=True)\n",
    "os.makedirs(TIMING_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5c07aa-d8da-4112-b512-5a22dbb446b6",
   "metadata": {},
   "source": [
    "#### 3.1.3 Get the pollen time series\n",
    "1. Let's load the datset and check that it has the \"date\" column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b448a3b1-b05f-406d-b0af-5c262b849453",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T14:25:06.017189Z",
     "iopub.status.busy": "2025-07-28T14:25:06.017138Z",
     "iopub.status.idle": "2025-07-28T14:25:06.031375Z",
     "shell.execute_reply": "2025-07-28T14:25:06.031145Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(\"../datasets/AlnusOurense9322.csv\")\n",
    "\n",
    "if \"date\" in df.columns:\n",
    "    # Set the \"date\" column as the index\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"], format=\"%d-%m-%Y\")\n",
    "    df.set_index(\"date\", inplace=True)\n",
    "else:\n",
    "    raise ValueError(\"Dataset must contain a 'date' column.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba9c36d-d445-4ab5-b528-787dc957d03a",
   "metadata": {},
   "source": [
    "2. Let's get the pollen time series from the dataset over the required time period (en, endogenous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05eab0da-e236-4200-9c8f-6d1654de5cd9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T20:09:36.097963Z",
     "start_time": "2025-05-02T20:09:34.620413Z"
    },
    "execution": {
     "iopub.execute_input": "2025-07-28T14:25:06.032134Z",
     "iopub.status.busy": "2025-07-28T14:25:06.032076Z",
     "iopub.status.idle": "2025-07-28T14:25:06.033857Z",
     "shell.execute_reply": "2025-07-28T14:25:06.033733Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get the pandas.Series pollen and filters the data by years \n",
    "en = df[(df.index >= pd.Timestamp(START_TRAINING)) & (df.index <= pd.Timestamp(END_DATE))][\"pollen\"]\n",
    "\n",
    "# Force daily frequency\n",
    "en = en.asfreq(\"D\") \n",
    "\n",
    "ex = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d7edee-7385-42c9-98cf-09d6783466f1",
   "metadata": {},
   "source": [
    "#### 3.1.4 Specifying the forecasting horizon\n",
    "\n",
    "We are going to do a prediction with the forecasting horizon of 1 week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "139aecf6-b077-4aeb-a13b-4ddbd1982d5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T14:25:06.034597Z",
     "iopub.status.busy": "2025-07-28T14:25:06.034544Z",
     "iopub.status.idle": "2025-07-28T14:25:06.383139Z",
     "shell.execute_reply": "2025-07-28T14:25:06.382934Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ForecastingHorizon([1, 2, 3, 4, 5, 6, 7], dtype='int64', is_relative=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sktime.forecasting.base import ForecastingHorizon\n",
    "import numpy as np\n",
    "\n",
    "fh = ForecastingHorizon(np.arange(1, HORIZON_SIZE+1), is_relative=True)\n",
    "fh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc20ae3d-7d7f-4562-8779-710c11400dd4",
   "metadata": {},
   "source": [
    "#### 3.1.5 Specifying the forecasting algorithm\n",
    "\n",
    "To make forecasts, a forecasting algorithm needs to be specified. This is done using a scikit-learn-like interface. Most importantly, all sktime forecasters follow the same interface, so the preceding and remaining steps are the same, no matter which forecaster is being chosen.\n",
    "\n",
    "We will work with all the available versions of **MOIRAI**: [MOIRAI versions](https://huggingface.co/collections/sktime/moirai-variations-66ba3bc9f1dfeeafaed3b974)\n",
    "\n",
    "**We'll also be testing the deterministic and stochastic model configurations**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3902e0de-d345-4fab-94ff-daa76bf188a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T14:25:06.384009Z",
     "iopub.status.busy": "2025-07-28T14:25:06.383897Z",
     "iopub.status.idle": "2025-07-28T14:25:08.286306Z",
     "shell.execute_reply": "2025-07-28T14:25:08.286068Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michi/miniconda3/envs/ppf-chronos-manual/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michi/miniconda3/envs/ppf-chronos-manual/lib/python3.12/site-packages/gluonts/json.py:102: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sktime.forecasting.moirai_forecaster import MOIRAIForecaster\n",
    "\n",
    "# Moirai models\n",
    "# Adding deterministic models\n",
    "moirai_models = {\n",
    "    f\"moirai.deterministic.{size}\": MOIRAIForecaster(\n",
    "        checkpoint_path=f\"sktime/moirai-1.0-R-{size}\",\n",
    "        context_length=INPUT_SIZE,\n",
    "        patch_size=32,\n",
    "        #num_samples=100,\n",
    "        #num_feat_dynamic_real=3,\n",
    "        #num_past_feat_dynamic_real=0,\n",
    "        map_location=None,\n",
    "        #target_dim= 1,\n",
    "        broadcasting=False,\n",
    "        deterministic=True,\n",
    "        batch_size=32,\n",
    "        use_source_package=False\n",
    "    )\n",
    "    for size in [\"small\", \"base\", \"large\"]\n",
    "}\n",
    "\n",
    "# Adding stochastic models\n",
    "moirai_models.update({\n",
    "    f\"moirai.stochastic.{size}\": MOIRAIForecaster(\n",
    "        checkpoint_path=f\"sktime/moirai-1.0-R-{size}\",\n",
    "        context_length=INPUT_SIZE,\n",
    "        patch_size=32,\n",
    "        # num_samples=100,\n",
    "        #num_feat_dynamic_real=3,\n",
    "        #num_past_feat_dynamic_real=0,\n",
    "        map_location=None,\n",
    "        #target_dim=1,\n",
    "        broadcasting=False,\n",
    "        deterministic=False,\n",
    "        batch_size=32,\n",
    "        use_source_package=False\n",
    "    )\n",
    "    for size in [\"small\", \"base\", \"large\"]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bff8b77-74a9-4b11-b535-2b3d5f574c43",
   "metadata": {},
   "source": [
    "#### 3.1.5 Defining the splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c70d9bc-5394-4547-bdb4-b0d32b017e3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T14:25:08.287134Z",
     "iopub.status.busy": "2025-07-28T14:25:08.287006Z",
     "iopub.status.idle": "2025-07-28T14:25:08.290451Z",
     "shell.execute_reply": "2025-07-28T14:25:08.290317Z"
    }
   },
   "outputs": [],
   "source": [
    "from sktime.forecasting.model_selection import SlidingWindowSplitter\n",
    "\n",
    "cv = SlidingWindowSplitter(fh=fh, window_length=INPUT_SIZE , step_length=1, start_with_window=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fac5f9-3e49-42b7-84bd-8b71616af8a7",
   "metadata": {},
   "source": [
    "#### 3.1.6 Requesting pollen forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "360adb36-5bbf-48b5-925b-9868962a9b53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T14:25:08.291351Z",
     "iopub.status.busy": "2025-07-28T14:25:08.291293Z",
     "iopub.status.idle": "2025-07-28T14:37:24.982704Z",
     "shell.execute_reply": "2025-07-28T14:37:24.982397Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting: 1998-06-27 00:00:00 - 2023-01-06 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predictions to: ../outputs/predictions/moirai.deterministic.small_0_365_7_without_covariates.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting: 1998-06-27 00:00:00 - 2023-01-06 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predictions to: ../outputs/predictions/moirai.deterministic.base_0_365_7_without_covariates.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting: 1998-06-27 00:00:00 - 2023-01-06 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predictions to: ../outputs/predictions/moirai.deterministic.large_0_365_7_without_covariates.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting: 1998-06-27 00:00:00 - 2023-01-06 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predictions to: ../outputs/predictions/moirai.stochastic.small_0_365_7_without_covariates.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting: 1998-06-27 00:00:00 - 2023-01-06 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predictions to: ../outputs/predictions/moirai.stochastic.base_0_365_7_without_covariates.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting: 1998-06-27 00:00:00 - 2023-01-06 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predictions to: ../outputs/predictions/moirai.stochastic.large_0_365_7_without_covariates.csv\n"
     ]
    }
   ],
   "source": [
    "from get_predictions import predict\n",
    "\n",
    "for name, model in moirai_models.items():    \n",
    "    result, fit_time, predict_time = predict(\n",
    "        model=model,\n",
    "        model_name=name,\n",
    "        start_year = START_YEAR,\n",
    "        end_year = END_YEAR,\n",
    "        y=en,\n",
    "        X=None,      \n",
    "        input_size=INPUT_SIZE,\n",
    "        train_size=TRAIN_SIZE, \n",
    "        offset_days = OFFSET_DAYS,\n",
    "        splitter=cv,\n",
    "        start_date = START_DATE,\n",
    "        amount_missing_data=amount_missing_data,\n",
    "        predictions_dir=PREDICTIONS_DIR,\n",
    "        timing_dir=TIMING_DIR\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a6a2503baa0c8c",
   "metadata": {},
   "source": [
    "## References:\n",
    "\n",
    "- [Moirai Adapter](https://github.com/sktime/sktime/blob/main/sktime/forecasting/moirai_forecaster.py#L21-L653) Source Code used by Sktime\n",
    "- [MoiraiForecaster](https://www.sktime.net/en/latest/api_reference/auto_generated/sktime.forecasting.moirai_forecaster.MOIRAIForecaster.html#rb64756c851d6-1) Sktime API\n",
    "- [Huggingface Moirai Variations](https://huggingface.co/collections/sktime/moirai-variations-66ba3bc9f1dfeeafaed3b974) \n",
    "- [Moirai Paper](https://arxiv.org/pdf/2402.02592)\n",
    "- [Official GitHub Repo](https://github.com/SalesforceAIResearch/uni2ts?tab=readme-ov-file#-getting-started)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07cfa4d5-d343-44a6-84fe-7c30b52ffb47",
   "metadata": {},
   "source": [
    "**➡️ [Next notebook: 02-02_Forecasting_with_Chronos](../notebooks/02-02_Forecasting_with_Chronos.ipynb)**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
